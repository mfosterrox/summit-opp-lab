= {lab_name}

== Introduction

In this lab, we aim to demonstrate the value-added service available to customers who purchase OpenShift Platform Plus subscriptions, which can benefit enterprises that need to manage multiple cluster deployments in an organized and security-focused manner. OpenShift Platform Plus contains all of the features that you may be familiar with in a standard OpenShift Container Platform subscription, but with the bonus of including four additional components for advanced management and functionality:  

* Red Hat Advanced Cluster Management for Kubernetes (RHACM)
* Red Hat Advanced Cluster Security for Kubernetes (RHACS)
* Red Hat Quay (Quay)
* Red Hat OpenShift Data Foundation (RHODF)

In this lab, participants can expect to gain a comprehensive understanding of the advanced capabilities provided by making use of these products to perform such as setting up a private registry for hosting images, deploying clusters and setting up global policies to make cluster management more straightforward, and analyzing the security profile of their clusters and applications by creating application enforcement policies and viewing image and network graph information to understand possible vulnerabilities in their deployments. 

Overall, this workshop promises to be a valuable learning experience for anyone looking to expand their knowledge of the value provided by purchasing a subscription for OpenShift Platform Plus.

== OpenShift Platform Plus applications

=== Red Hat Advanced Cluster Management for Kubernetes (RHACM)

Red Hat Advanced Cluster Management for Kubernetes is a multi-cluster management solution that helps organizations manage their Kubernetes clusters and applications across hybrid and multicloud environments. It provides a unified management console, policy-based governance, observability, and automation capabilities, helping to simplify and streamline Kubernetes management operations.

In this workshop we will demonstrate the value of RHACM with the following activities:

. Demonstrate the ease of deploying new clusters in the cloud.
. Create an application deployment policy across managed clusters.
. Create a governance policy to help secure our clusters.

=== Red Hat Advanced Cluster Security for Kubernetes (RHACS)

Red Hat Advanced Cluster Security for Kubernetes is a Kubernetes-native security platform that equips you to build, deploy, and run cloud-native applications with more security. The solution helps protect containerized Kubernetes workloads in all major clouds and hybrid platforms, including Red Hat OpenShift, Amazon Elastic Kubernetes Service (EKS), Microsoft Azure Kubernetes Service (AKS), and Google Kubernetes Engine (GKE).

In this workshop we will demonstrate the value of RHACS with the following activities:

. Examine the RHACS console in order to explore vulnerable workloads.
. Explore network graphs and metrics created by observing applications running in the cluster.
. Demonstrate deployment and runtime enforcement options to prevent security issues.

=== Red Hat Quay (Quay)

Red Hat Quay is a security-focused and scalable private registry platform for managing content across globally distributed datacenter and cloud environments. It provides a single and resilient content repository for delivering containerized software to development and production across Red Hat OpenShift and Kubernetes clusters. Red Hat Quay is a distributed and highly available container image registry for your enterprise.

In this workshop we will demonstrate the value of Quay with the following activities:

. Easily Install and Configure Quay from the OpenShift OperatorHub.
. Configure a private registry for use with our clusters.
. Upload and explore an image with our newly created registry.

=== Red Hat OpenShift Data Foundation (RHODF)

Red Hat OpenShift Data Foundation—previously Red Hat OpenShift Container Storage—is software-defined storage for containers. Red Hat OpenShift Data Foundation helps teams develop and deploy applications quickly and efficiently across clouds.

NOTE: In this workshop we will not use ODF explicitly, but it will be used as the primary backing storage for our Quay registry, and any other applications we deploy in the cluster that need persistent storage.

== Environment Overview and Access

You will be interacting with an OpenShift 4 cluster that is running on Amazon Web Services. This cluster will act as a central hub for the actions you are performing in your environment.
The basics of the OpenShift 4 installation have been completed in advance. The OpenShift cluster is essentially set to all defaults and looks like the following:

. Three control-plane nodes
. Three worker nodes
. One bastion host

In addition you will have an additional working cluster provisioned with Hosted Control Planes in AWS, and be able to deploy your own cluster as a part of the lab tasks. 

=== Working Environment

IMPORTANT: All of the commands, walkthroughs, images, and warnings for the lab can be found in the this lab guide, called the "Showroom lab guide" 

====  OpenShift console access & RHACM console access

NOTE: The Red Hat Advanced Cluster Management for Kubernetes (RHACM) Console is now integrated with OpenShift Console, to access it please select *All Clusters* from the dropdown menu once you log in. 

Your OpenShift cluster console is available at: {openshift_console_url}

Administrator login is available with:

[cols="1,1"]
|===
*User:*| kubeadmin |
*Password:*| {openshift_kubeadmin_password} |
|===

==== RHACS console access

Your RHACS Console is available at: {acs_route}[window=blank]

Administrator login is available with:

[cols="1,1"]
|===
*RHACS Console Username:* | {acs_portal_username} |
*RHACS Console Password:* | {acs_portal_password} |
|===

==== Quay console access

Your Red Hat Quay console is available at: {quay_console_url}[window=blank]

Administrator login is available with:

[cols="1,1"]
|===
*Quay Console Username:* | {quay_admin_username} |
*Quay Console Password:* | {quay_admin_password} |
|===

==== Bastion Access

A RHEL bastion host is available with common utilities pre-installed and OpenShift command line access pre-configured.

For SSH access to the bastion:

[cols="1,1"]
|===
*Bastion Hostname:* | {bastion_public_hostname} |
*Bastion Username:* | {bastion_ssh_user_name} |
*Bastion Password:* | {bastion_ssh_password} |
|===

. Enter the ssh command in the Showroom lab terminal

[source,sh,subs="attributes",role=execute]

----
ssh {bastion_ssh_user_name}@{bastion_public_hostname}
----

*Sample output*
[source,bash]
----
The authenticity of host 'ec2-18-218-57-221.us-east-2.compute.amazonaws.com ($IP_ADDRESS)' can't be established.
ED25519 key fingerprint is SHA256:X2AGqDUv+yVqYGGh0Ul8b8awRM0kWXgAAzePskZ6ixo.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])?
----

[start=2]
. Type "Yes"


. Enter the SSH password (*{bastion_ssh_password}*) when prompted.

== Demo applications setup

IMPORTANT: Make sure to finish all of the following steps and ensure the vulnerable applications deploy properly. We will use these applications in later modules. 

=== Download, build and push the Java demo container image to Quay via the Bastion VM

To demonstrate Quay's functionality, we can pull an image from a public repository and upload it to our newly created registry. We can push container images to Quay as long as we have the correct credentials to set up new registries. To demonstrate this functionality, we are going to use the ctf-web-to-system container image.

IMPORTANT: You will need to complete the following commands in the *Bastion VM* Please SSH to it (If you have not already) by using the following command:

[source,sh,subs="attributes",role=execute]

----
ssh {bastion_ssh_user_name}@{bastion_public_hostname}
----

Make sure you use the password '{bastion_ssh_password}' when prompted.

. Let's export a few variable to make our life easier

[source,sh,subs="attributes",role=execute]
----
export QUAY_USER={quay_admin_username}
----

[start=2]

. Set the Quay URL variable 

IMPORTANT: Make sure to REMOVE the *https://* from the URL command below.

[source,sh,subs="attributes",role=execute]
----
export QUAY_URL={quay_console_url} #remove https://
----

[start=3]
. Using the terminal on the bastion host, login to quay using the Podman CLI as shown below:

[source,sh,subs="attributes",role=execute]
----
podman login $QUAY_URL
----

NOTE: Use the quay admin credentials, Username: *{quay_admin_username}* & password: *{quay_admin_password}*. You can create unique user and group credentials in Quay for proper segmentation. 

*Sample output*
[source,bash]
----
Username: quayadmin
Password:
Login Succeeded!
----

[start=4]
. Pull the Java container image with the following CLI command:

[source,sh,subs="attributes",role=execute]
----
podman pull quay.io/jechoisec/ctf-web-to-system-01
----

*Sample output*
[source,bash]
----
Trying to pull quay.io/jechoisec/ctf-web-to-system-01:latest...
Getting image source signatures
Copying blob 37aaf24cf781 done 
...
...
Copying config 1cbb2b7908 done  
Writing manifest to image destination
1cbb2b79086961e34d06f301b2fa15d2a7e359e49cfe67c06b6227f6f0005149
----

[start=5]
. Now that you have a copy of the Java container image locally. You must tag the image before pushing it to Quay. 

[source,sh,subs="attributes",role=execute]
----
podman tag quay.io/jechoisec/ctf-web-to-system-01 $QUAY_URL/$QUAY_USER/ctf-web-to-system:1.0
----

NOTE: Quay will automatically create a private registry to store our Java appplication. We will need to make it a public repository to be able to pull the miage without credentials. We will do this in the following module

[start=6]
. The last step is to push the image to Quay.

[source,sh,subs="attributes",role=execute]
----
podman push $QUAY_URL/$QUAY_USER/ctf-web-to-system:1.0 --remove-signatures
----

*Sample output*
[source,bash]
----
Copying blob 3113fb957b33 done 
...
...
Copying config 1cbb2b7908 done  
Writing manifest to image destination
----

[start=6]

Perfect!

In the next module, we will browse through Quay to see the Java container app that you have tagged and pushed. The apple will be deployed into the cluster in the next step.

